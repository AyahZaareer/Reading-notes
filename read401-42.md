# Ethics


## Ethics in the workplace
### [The code I’m still ashamed of](https://medium.freecodecamp.org/the-code-im-still-ashamed-of-e4c021dff55e)
  - As developers, we are often one of the last lines of defense against potentially dangerous and unethical practices." This quote really stood out to me, and I haven't necessarily thought of it that way before, that we are one of the last passes through before something gets put out into the world.
  - "Take a stand and ensure that our ethics are ever present in our code." This was another piece of the article that stood out to me, keeping aware and making sure that we're always considering what's at play. That we don't just write lines of code as prescribed, but that we think at a high level what they are doing.


## Ethics in Technology
### [Big Data is our Civil Rights issue](http://solveforinteresting.com/big-data-is-our-generations-civil-rights-issue-and-we-dont-know-it/)
  - You decide what data is about the moment you define it's schema.
  - when things become so cheap that they’re practically free, big changes happen—just look at the advent of steam power, or the copying of digital music, or the rise of home printing. Abundance replaces scarcity, and we invent new business models.
  - With the new, data-is-abundant model, we collect first and ask questions later. The schema comes after the collection. Indeed, Big Data success stories like Splunk, Palantir, and others are prized because of their ability to make sense of content well after it’s been collected—sometimes called a schema-less query. This means we collect information long before we decide what it’s for.

### [Will democracy survive big data and AI?](https://www.scientificamerican.com/article/will-democracy-survive-big-data-and-artificial-intelligence/)
  - One thing is clear: the way in which we organize the economy and society will change fundamentally. We are experiencing the largest transformation since the end of the Second World War; after the automation of production and the creation of self-driving cars the automation of society is next. With this, society is at a crossroads, which promises great opportunities, but also considerable risks. If we take the wrong decisions it could threaten our greatest historical achievements.
  - As smart devices become smarter and take strides towards sentience, it is our responsibility to mitigate the risks associated with big data and artificial intelligence. Companies are profiting from big data, supercomputers are surpassing the capabilities of humans, and jobs are rapidly being replaced by machines. Although innovation and technology have potential catastrophic consequences, we can’t ignore the potential benefits. Modern technology has created a global community and now more than ever, we have the tools and capability to come together for massive transformative change.. I strongly believe that humanity needs to be strategic and responsible when it comes to future innovation.


## Tech Company Principles
### [Google AI Principles](https://www.blog.google/technology/ai/ai-principles/)
  -  AI is computer programming that learns and adapts. It can’t solve every problem, but its potential to improve our lives is profound. At Google, we use AI to make products more useful—from email that’s spam-free and easier to compose, to a digital assistant you can speak to naturally, to photos that pop the fun stuff out for you to enjoy.
  -  that AI should:

       1. Be socially beneficial
       2. Avoid creating or reinforcing unfair bias. 
       3. Be built and tested for safety.
       4. Be accountable to people
       5. Incorporate privacy design principles.
       6. Uphold high standards of scientific excellence.
       7. Be made available for uses that accord with these principles. 
